{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a38734",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "<li>Pandas is an open-source Python package that is built on top of NumPy used for working with data sets.</li> \n",
    "<li>The name \"Pandas\" has a reference to <b>\"Python Data Analysis\".</b></li>\n",
    "<li>Pandas is considered to be one of the best data-wrangling packages.</li>\n",
    "<li>Pandas offers user-friendly, easy-to-use data structures and analysis tools for analyzing, cleaning, exploring and manipulating data.</li>\n",
    "<li>It also functions well with various other data science Python modules.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79079ab0",
   "metadata": {},
   "source": [
    "# Difference Between NumPy & Pandas\n",
    "\n",
    "![](images/pandas_vs_numpy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ede164",
   "metadata": {},
   "source": [
    "## Why Use Pandas?\n",
    "\n",
    "<li>Pandas is known for its exceptional ability to represent and organize data.</li>\n",
    "<li>The Pandas library was created to be able to work with large datasets faster and more efficiently than any other library.</li>\n",
    "<li>It excels at analyzing huge amounts of data.Pandas allows us to analyze big data and make conclusions based on statistical theories.</li>\n",
    "<li>Pandas can clean messy data sets, and make them readable and relevant.</li>\n",
    "<li>By combining the functionality of Matplotlib and NumPy, Pandas offers users a powerful tool for performing <b>data analytics and visualization.</b></li>\n",
    "<li>Data can be imported to Pandas from a variety of file formats, such as Csv, SQL, Excel, and JSON, among others.</li>\n",
    "<li>Pandas is a versatile and marketable skill set for data analysts and data scientists that can gain the attention of employers.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97011979",
   "metadata": {},
   "source": [
    "## Installation Of Pandas\n",
    "<li>Go to your terminal, open and activate your virtual environment and then use the following commands for installing pandas.</li>\n",
    "\n",
    "<code>\n",
    "    pip install pandas\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a699b7dc",
   "metadata": {},
   "source": [
    "## Importing Pandas\n",
    "<li>We need to import pandas if we want to create a pandas dataframe and perform any analysis on them.</li>\n",
    "<li>We can import pandas package using the following command:</li>\n",
    "<code>\n",
    "    import pandas as pd\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a52ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4140b6ef",
   "metadata": {},
   "source": [
    "## How To Create A Pandas DataFrame\n",
    "<li>A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional array, arranged in a table like structure with rows and columns.</li>\n",
    "<li>We can create a basic pandas dataframe by various methods.</li>\n",
    "<li>Let's discuss some of the methods to create the given dataframes:</li>\n",
    "\n",
    "![](images/dataframe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75cbcf",
   "metadata": {},
   "source": [
    "### 1. From Python Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795c295",
   "metadata": {},
   "source": [
    "### 2. From a list of dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d5b64",
   "metadata": {},
   "source": [
    "### 3. From a list of tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8ee6c",
   "metadata": {},
   "source": [
    "### 4. From list of lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674a00fa",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "<li>Read 'weather_data.csv' file using csv reader.</li>\n",
    "<li>Store the data inside the csv file into a list of lists.</li>\n",
    "<li>Then create a pandas dataframe using list of list.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61c9a6a",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>1. Read 'imports-85.data' file using file reader.</li>\n",
    "<li>2. Store the data present inside the file into a list of list.</li>\n",
    "<li>3. Create a pandas dataframe using list of lists.</li>\n",
    "<li>4. For column name, we can use the columns variable given below.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['symboling', 'normalized_losses', 'make', 'fuel_type', 'aspiration', 'num_of_doors',\n",
    "          'body_style', 'drive_wheels', 'engine_location', 'wheel_base', 'length', 'width', \n",
    "           'height', 'curb_weight', 'engine_type', 'num_of_cylinders', 'engine_size', 'fuel_system',\n",
    "          'bore', 'stroke', 'compression', 'horsepower', 'peak_rpm', 'city_mpg', 'highway_mpg', \n",
    "           'price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d8b79",
   "metadata": {},
   "source": [
    "### 5. Pandas Dataframe From Csv files\n",
    "\n",
    "<li>We can load a csv file and create a dataframe out of the data present inside a csv file using pandas.</li>\n",
    "<li>We have <b>.read_csv()</b> method to read a csv file and create a pandas dataframe from the dataset.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ac0ad",
   "metadata": {},
   "source": [
    "### Reading a csv file using skiprows and header parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a3a1c",
   "metadata": {},
   "source": [
    "#### Reading a csv file without header and giving names to the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2fb6da",
   "metadata": {},
   "source": [
    "#### Read limited data from a csv file using nrows parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b269e47",
   "metadata": {},
   "source": [
    "#### Reading csv files with na_values parameters ('weather_data.csv' file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70933041",
   "metadata": {},
   "source": [
    "#### Write a pandas dataframe to a csv file\n",
    "<li>We can write a pandas dataframe to a csv file using .to_csv() method.</li>\n",
    "<li>You can specify any name to the csv file while writing a pandas dataframe into a csv file.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcbf58",
   "metadata": {},
   "source": [
    "### 6. Pandas Dataframe From Xcel files\n",
    "\n",
    "<li>We can load an excel file with <b>.xlsx</b> extension and create a dataframe out of the data present inside an excel file using pandas.</li>\n",
    "<li>We have <b>.read_excel()</b> method to read a csv file and create a pandas dataframe from the dataset.</li>\n",
    "<li>We also need to install <b>openpyxl</b> for working with excel files.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98ce1b",
   "metadata": {},
   "source": [
    "#### Writing to an excel file\n",
    "<li>We can write a pandas dataframe into a excel file using .to_excel() method.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa283a0e",
   "metadata": {},
   "source": [
    "#### Using head() and tail() method to see top 5 and last 5 rows\n",
    "<li>To view the first few rows of our dataframe, we can use the DataFrame.head() method.</li>\n",
    "<li>By default, it returns the first five rows of our dataframe.</li>\n",
    "<li>However, it also accepts an optional integer parameter, which specifies the number of rows.</li>\n",
    "\n",
    "<li>Similarly, to view the last few rows of our dataframe, we can use the DataFrame.tail() method.</li>\n",
    "<li>By default, it returns the last five rows of our dataframe.</li>\n",
    "<li>However, it also accepts an optional integer parameter, which specifies the number of rows.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1955ec8",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "\n",
    "<li>Use the head() method to select the first 6 rows.</li>\n",
    "<li>Use the tail() method to select the last 8 rows.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823ed4e",
   "metadata": {},
   "source": [
    "#### Finding the column names from the dataframe\n",
    "<li>We have df.columns attributes to check the name of columns in the pandas dataframe.</li>\n",
    "<li>Similarly, we have df.values attributes to check the data present in the pandas dataframe.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755f4e92",
   "metadata": {},
   "source": [
    "#### Checking the type of your dataframe \n",
    "<li>Another feature that makes pandas better for working with data is that dataframes can contain more than one data type.</li>\n",
    "<li>Axis values can have string labels, not just numeric ones.</li>\n",
    "<li>Dataframes can contain columns with multiple data types: including integer, float, and string.</li>\n",
    "<li>We can use the DataFrame.dtypes attribute (similar to NumPy) to return information about the types of each column.</li>\n",
    "<li>When we import data, pandas attempts to guess the correct dtype for each column.</li>\n",
    "<li>Generally, pandas does well with this, which means we don't need to worry about specifying dtypes every time we start to work with data.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7209ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df_nan.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1518ae8e",
   "metadata": {},
   "source": [
    "#### Datatypes Information\n",
    "<li>We can get the shape of the dataset using <b>.shape()</b> method.</li>\n",
    "<li><b>.shape()</b> method returns the tuple datatype containing the number of rows and number of columns in the dataset.</li>\n",
    "<li>If we wanted an overview of all the dtypes used in our dataframe, we can use <b>.info()</b> method.</li>\n",
    "<li>Note that <b>DataFrame.info()</b> prints the information, rather than returning it, so we can't assign it to a variable.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf679a",
   "metadata": {},
   "source": [
    "#### Checking the null values in the pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3444a637",
   "metadata": {},
   "source": [
    "#### set_index() and reset_index() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60c853",
   "metadata": {},
   "source": [
    "#### Selecting a column from a pandas DataFrame\n",
    "\n",
    "<li>Since our axis in pandas have labels, we can select data using those labels.</li> \n",
    "<li>Unlike in NumPy, we donot need to know the exact index location of a pandas dataframe.</li>\n",
    "<li>To do this, we can use the DataFrame.loc[] attribute. The syntax for DataFrame.loc[] is:</li>\n",
    "<code>\n",
    "df.loc[row_label, column_label]\n",
    "</code>\n",
    "\n",
    "<li>We can use the following shortcut to select a single column:</li>\n",
    "<code>\n",
    "df[\"column_name\"]\n",
    "</code>\n",
    "\n",
    "<li>This style of selecting columns is very common.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89546f82",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "<li>Read <b>'appointment_schedule.csv'</b> file using pandas.</li>\n",
    "<li>Select the <b>'name'</b> column from the given dataset and store to <b>'appointment_names'</b> variable.</li>\n",
    "<li>Use Python's <b>type()</b> function to assign the type of name column to <b>name_type</b>.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc59c3",
   "metadata": {},
   "source": [
    "#### Pandas Series\n",
    "<li>Series is the pandas type for one-dimensional objects.</li>\n",
    "<li>Anytime you see a 1D pandas object, it will be a series. Anytime you see a 2D pandas object, it will be a dataframe.</li>\n",
    "<li>A dataframe is a collection of series objects, which is similar to how pandas stores the data behind the scenes.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fe1187",
   "metadata": {},
   "source": [
    "#### Adding a column in a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410deeaa",
   "metadata": {},
   "source": [
    "### Selecting Multiple Columns From the DataFrame\n",
    "\n",
    "![](images/selecting_columns.png)\n",
    "\n",
    "<li>We can select multiple columns from the dataframe by using the following codes:</li>\n",
    "<code>\n",
    "    df.loc[:, [\"col1\", \"col2\"]]\n",
    "</code>\n",
    "\n",
    "<li>We can use syntax shortcuts for selecting multiple columns by using the following syntax:</li>\n",
    "<code>\n",
    "    df[[\"col1\", \"col2\"]]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0439cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df = pd.read_csv('car_details.csv')\n",
    "car_details_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f78cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df.loc[:, ['name', 'selling_price', 'km_driven']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2356fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_df[['name', 'selling_price', 'km_driven']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_details_limited = car_details_df.drop(['year', 'fuel', 'seller_type',\n",
    "                                          'transmission', 'owner'],\n",
    "                                          axis = 1)\n",
    "car_details_limited.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bb5f7",
   "metadata": {},
   "source": [
    "#### Selecting Rows From A Pandas DataFrame\n",
    "\n",
    "<li>Now that we've learned how to select columns by label, let's learn how to select rows using the labels of the index axis.</li>\n",
    "<li>We can use the same syntax to select rows from a dataframe as we do for columns:</li>\n",
    "<code>\n",
    "    df.loc[row_label, column_label]\n",
    "</code>\n",
    "\n",
    "![](images/selecting_one_row.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abbbda2",
   "metadata": {},
   "source": [
    "### Selecting Multiple Rows From the DataFrame\n",
    "\n",
    "![](images/selecting_multiple_rows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b1bca",
   "metadata": {},
   "source": [
    "#### Indexing & Slicing In Pandas DataFrame\n",
    "\n",
    "<li>We can slice a dataset from their rows as well as columns.</li>\n",
    "<li>If we have (5,5) shape data and we want first three rows and first three columns then we need to slice both rows and columns to get a desired shape.</li>\n",
    "<li>We have df.iloc() method which we can use to do indexing as well as slicing in a dataframe.</li>\n",
    "<li>Let's practice .iloc() method.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2a6a6",
   "metadata": {},
   "source": [
    "#### Datatype Conversion In Pandas\n",
    "\n",
    "<li>Pandas astype() is the one of the most important methods. It is used to change data type of a series.</li>\n",
    "<li>When a pandas dataframe is created from a csv file,the data type is set automatically.</li>\n",
    "<li>The datatype will not be what it actually should be at times and this is where we can use astype()  to get desired datatype.</li>\n",
    "<li>For example, a salary column could be imported as string but to do operations we have to convert it into float.</li>\n",
    "<li>astype() is used to do such data type conversions.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e22cf7",
   "metadata": {},
   "source": [
    "#### Value Counts Method\n",
    "\n",
    "<li>Since series and dataframes are two distinct objects, they have their own unique methods.</li>\n",
    "\n",
    "<li>Let's look at an example of a series method - the Series.value_counts() method.</li>\n",
    "\n",
    "<li>This method displays each unique non-null value in a column and their counts in order.</li>\n",
    "\n",
    "<li>value_counts() is a series only method, we get the following error if we try to use it for dataframes:</li>\n",
    "\n",
    "<code>\n",
    "    AttributeError: 'DataFrame' object has no attribute 'value_counts'\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e21f7",
   "metadata": {},
   "source": [
    "#### Creating a frequency table from value_counts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5254648",
   "metadata": {},
   "source": [
    "#### Renaming the column names in a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d48a664",
   "metadata": {},
   "source": [
    "#### Selecting Items From A Series Method\n",
    "\n",
    "<li>As with dataframes, we can use Series.loc[] to select items from a series using single labels, a list, or a slice object.</li>\n",
    "<li>We can also omit loc[] and use bracket shortcuts for all three:</li>\n",
    "\n",
    "![](images/selecting_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36bdfb5",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "<li>Use the value counts method to check the frequency count of different names from 'appointment_schedule.csv' file.</li>\n",
    "<li>Select only first row from the series.</li>\n",
    "<li>Select the first row and the last row from the series.</li>\n",
    "<li>Select the first five rows and the last five rows from the series.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5d6f3",
   "metadata": {},
   "source": [
    "#### DataFrame Vs DataSeries\n",
    "\n",
    "![](images/dataframe_vs_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a991f",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "![](images/pandas_selection_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58daf32",
   "metadata": {},
   "source": [
    "#### Vecotrized Operations In Pandas\n",
    "\n",
    "<li>We'll explore how pandas uses many of the concepts we learned in the NumPy.</li>\n",
    "<li>Because pandas is designed to operate like NumPy, a lot of concepts and methods from Numpy are supported.</li>\n",
    "<li>Recall that one of the ways NumPy makes working with data easier is with vectorized operations.</li>\n",
    "<li>Just like with NumPy, we can use any of the standard Python numeric operators with series, including:</li>\n",
    "<code>\n",
    "    series_a + series_b - Addition\n",
    "    series_a - series_b - Subtraction\n",
    "    series_a * series_b - Multiplication\n",
    "    series_a / series_b - Division\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0db341",
   "metadata": {},
   "source": [
    "#### Some Statistical Functions In Pandas\n",
    "\n",
    "<li>Like NumPy, Pandas supports many descriptive stats methods such as mean, median, mode, min, max and so on.</li>\n",
    "<li>Here are a few of the most useful ones.</li>\n",
    "<code>\n",
    "Series.max()\n",
    "Series.min()\n",
    "Series.mean()\n",
    "Series.median()\n",
    "Series.mode()\n",
    "Series.sum()\n",
    "</code>\n",
    "<li>We can calculate the average value of a particular column(series) using df.column_name.mean().</li>\n",
    "<li>For calculating the minimum value in a particular column(series), we can use df.column_name.min().</li>\n",
    "<li>Similarly, for calculating the maximum value in a particular column(series), we can use df.column_name.max().</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6ea53",
   "metadata": {},
   "source": [
    "#### Finding the descriptive statistics of the dataframe using .describe() method\n",
    "\n",
    "<li>Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset's distribution, excluding NaN values.</li>\n",
    "<li>describe() method in Pandas is used to compute descriptive statistics for all of your numeric columns.</li>\n",
    "<li>Analyzes both numeric and object series, as well as DataFrame column sets of mixed data types.</li>\n",
    "<li>The output will vary depending on what is provided.</li>\n",
    "<li>If we want to see the descriptive statistics of an object datatype then we have to specify <b>df.describe(include = \"O\")</b></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2ba4a",
   "metadata": {},
   "source": [
    "#### Assigning Values With Pandas\n",
    "\n",
    "<li>Just like in NumPy, the same techniques that we use to select data could be used for assignment.</li>\n",
    "\n",
    "<li>When we selected a whole column by label and used assignment, we assigned the value to every item in that column.</li>\n",
    "\n",
    "<li>By providing labels for both axes, we can assign them to a single value within our dataframe.</li>\n",
    "\n",
    "<code>\n",
    "    df.loc[row_label, col_label] = assignment_value\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aede61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caf9b17d",
   "metadata": {},
   "source": [
    "#### Using Boolean Indexing With Pandas Objects (Selection With Condition In Pandas)\n",
    "<li>We can assign a value by using row label and column label in pandas.</li>\n",
    "<li>But what if we need to assign a same value to a group of similar rows with the same criteria.</li>\n",
    "<li> Instead, we can use boolean indexing to change all rows that meet the same criteria, just like we did with NumPy.</li>\n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li>Equals: df['series'] == value</li>\n",
    "    <li>Not Equals: df['series'] != value</li>\n",
    "    <li>Less than: df['series'] < value</li>\n",
    "    <li>Less than or equal to: df['series'] <= value</li>\n",
    "    <li>Greater than: df['series'] > value</li>\n",
    "    <li>Greater than or equal to: df['series'] >= value</li>\n",
    "</ol>\n",
    "<li>These conditions can be used in several ways, most commonly inside .loc to select values with conditions.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64feeff6",
   "metadata": {},
   "source": [
    "### Using Pandas Method To Create a Boolean Mask\n",
    "\n",
    "<li>In the last couple lessons, we used Python boolean operators to create boolean masks to select subsets of data.</li>\n",
    "    \n",
    "<li>There are also a number of pandas methods that return boolean masks useful for exploring data.</li>\n",
    "\n",
    "<li>Two examples are the Series.isnull() method and Series.notnull() method.</li>\n",
    "<li>Series.isnull() method can be used to select either rows that contain null (or NaN) values for a certain column.</li>\n",
    "<li>Similarly, Series.notnull() method is used to select rows that do not contain null values for a certain column.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f9989",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "<li>Read 'Fortune_1000.csv' file using pandas read_csv() method and store it in a variable named f1000.</li>\n",
    "<li>Select the rank, revenues, and rank_change columns in f1000. Then, use the df.head() method to select first five rows.</li>\n",
    "<li>Select just the fifth row of the f1000 dataframe. Assign the result to fifth_row using iloc.</li>\n",
    "<li>Select the value in first row of the company column. Assign the result to company_value.</li>\n",
    "<li>Select the last three rows of the f1000 dataframe. Assign the result to last_three_rows.</li>\n",
    "<li>Select the first to seventh rows and the first five columns of the f1000 dataframe.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e903aad",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "<li>Use the Series.isnull() method to select all rows from f1000 that have a null value for the prev_rank column.</li>\n",
    "<li>Select only the company, rank, and previous_rank columns where previous_rank column is null.</li>\n",
    "<li>Use the Series.notnull() method to select all rows from f1000 that have a non-null value for the previous_rank column.</li></b>\n",
    "<li>From the previously_ranked dataframe, subtract the rank column from the previous_rank column.</li>\n",
    "<li>Assign the values in the rank_change to a new column in the f1000 dataframe, \"rank_change\".</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a3f21",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "<li>Select all companies with revenues over 100 thousands and negative profits from the f1000 dataframe.</li>\n",
    "\n",
    "##### Instructions\n",
    "\n",
    "<li>Create a boolean array that selects the companies with revenues greater than 100 thousands.</li>\n",
    "<li>Create a boolean array that selects the companies with profits less than 0.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f0aa4",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "<li>Select all rows for companies whose city value is either Brazil or Venezuela.</li>\n",
    "<li>Select the first five companies in the Technology sector for which the city is not the \"Boston\" from the f1000 dataframe.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e66d65",
   "metadata": {},
   "source": [
    "#### Sorting Values\n",
    "<li>We can use the DataFrame.sort_values() method to sort the rows on a particular column.</li>\n",
    "<li>To do so, we pass the column name to the method:</li>\n",
    "<code>\n",
    "sorted_rows = df.sort_values(\"column_name\")\n",
    "</code>\n",
    "<li>By default, the sort_values() method will sort the rows in ascending order — from smallest to largest.</li>\n",
    "<li>To sort the rows in descending order instead, we can set the ascending parameter to False:</li>\n",
    "<code>\n",
    "    sorted_rows = df.sort_values(\"column_name\", ascending=False)\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45766113",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>Read 'Fortune_1000.csv' using pandas read_csv() method.</li>\n",
    "<li>Find the company headquartered in Los Angeles with the largest number of employees.</li>\n",
    "<li>Select only the rows that have a city name equal to Los Angeles.</li>\n",
    "<li>Use DataFrame.sort_values() to sort those rows by the employees column in descending order.</li>\n",
    "<li>Use DataFrame.iloc[] to select the first row from the sorted dataframe.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa1f3f",
   "metadata": {},
   "source": [
    "### String Manipulation In Pandas DataFrame\n",
    "\n",
    "<li>String manipulation is the process of changing, parsing, splitting, 'cleaning' or analyzing strings.</li>\n",
    "<li>As we know that sometimes, data in the string is not suitable for manipulating the analysis or get a description of the data.</li>\n",
    "<li>But Python is known for its ability to manipulate strings.</li>\n",
    "<li>Pandas provides us the ways to manipulate to modify and process string data-frame using some builtin functions.</li>\n",
    "<li>Some of the most useful pandas string processing functions are as follows:</li>\n",
    "<ol>\n",
    "    <li><b>lower()</b></li>\n",
    "    <li><b>upper()</b></li>\n",
    "    <li><b>islower()</b></li>\n",
    "    <li><b>isupper()</b></li>\n",
    "    <li><b>isnumeric()</b></li>\n",
    "    <li><b>strip()</b></li>\n",
    "    <li><b>split()</b></li>\n",
    "    <li><b>len()</b></li>\n",
    "    <li><b>get_dummies()</b></li>\n",
    "    <li><b>startswith()</b></li>\n",
    "    <li><b>endswith()</b></li>\n",
    "    <li><b>replace()</b></li>\n",
    "    <li><b>contains()</b></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8f9ac",
   "metadata": {},
   "source": [
    "#### 1. lower(): \n",
    "<li>It converts all uppercase characters in strings in the dataframe to lower case and returns the lowercase strings in the result.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e716b946",
   "metadata": {},
   "source": [
    "#### 2. upper():\n",
    "<li>It converts all lowercase characters in strings in the dataframe to upper case and returns the uppercase strings in result.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086d672",
   "metadata": {},
   "source": [
    "#### 3. islower(): \n",
    "<li>It checks whether all characters in each string in the Data-Frame is in lower case or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb1f5d1",
   "metadata": {},
   "source": [
    "#### 4. isupper(): \n",
    "<li>It checks whether all characters in each string in the Data-Frame is in upper case or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462fcf07",
   "metadata": {},
   "source": [
    "#### 5. isnumeric():\n",
    "<li>It checks whether all characters in each string in the Data-Frame are numeric or not, and returns a Boolean value.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db0288",
   "metadata": {},
   "source": [
    "#### 6. strip():\n",
    "<li>If there are spaces at the beginning or end of a string, we should trim the strings to eliminate spaces using strip() method.</li>\n",
    "<li>It remove the extra spaces contained by a string in a DataFrame.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0cc7b",
   "metadata": {},
   "source": [
    "#### 7. split(‘ ‘):\n",
    "<li>It splits each string with the given pattern.</li>\n",
    "<li>Strings are split and the new elements after the performed split operation, are stored in a list.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0786d86",
   "metadata": {},
   "source": [
    "#### 8. len():\n",
    "<li>With the help of len() we can compute the length of each string in DataFrame.</li>\n",
    "<li>If there is empty data in a DataFrame, it returns NaN.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866234b9",
   "metadata": {},
   "source": [
    "#### 9. get_dummies(): \n",
    "<li>It returns the DataFrame with One-Hot Encoded values like we can see that it returns boolean value 1 if it exists in relative index or 0 if not exists.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53501fa7",
   "metadata": {},
   "source": [
    "#### 10. startswith(pattern):\n",
    "<li>It returns true if the element or string in the DataFrame Index starts with the pattern.</li>\n",
    "<li>If you wanted to filter out rows that startswith 'ind' then you can specify df[df[col].str.startswith('ind')</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d7983",
   "metadata": {},
   "source": [
    "#### 11. endswith(pattern):\n",
    "<li>It returns true if the element or string in the DataFrame Index ends with the pattern.</li>\n",
    "<li>If you wanted to filter out rows that ends with 'es' then you can specify df[df[col].str.endswith('es')</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85f839",
   "metadata": {},
   "source": [
    "#### 12. replace(a,b):\n",
    "<li>It replaces the value a with the value b.</li>\n",
    "<li>If you wanted to remove white space characters then you can use replace() method as:</li>\n",
    "<code>\n",
    "df[col_name].str.replace(\" \", \"\")\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0272a938",
   "metadata": {},
   "source": [
    "#### 13. contains():\n",
    "<li>contains() method checks whether the string contains a particular substring or not.</li>\n",
    "<li>The function is quite similar to replace() but instead of replacing the string itself it just returns the boolean value True or False.</li>\n",
    "<li>If a substring is present in a string, then it returns boolean value True else False.</li>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5a6dc",
   "metadata": {},
   "source": [
    "#### Handling Missing Values\n",
    "<li>We can use fillna() method in pandas to fill missing values using different ways.</li>\n",
    "<li>We can use interpolation method to make a guess on missing values.</li>\n",
    "<li>We can use dropna() method to drop rows with missing values.</li>\n",
    "<li>We can also fill missing values with the mean value, median value or the mode value depending on the values of columns.</li>\n",
    "<li>Filling missing values with mean and median is appropriate when the column has continuous values.</li>\n",
    "<li>If the data is categorical then filling missing values with mode is a good idea.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b01ebc",
   "metadata": {},
   "source": [
    "#### fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9793078",
   "metadata": {},
   "source": [
    "#### fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e2c03",
   "metadata": {},
   "source": [
    "#### Interpolate(Linear Interpolation)\n",
    "<li>method = time</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b3062",
   "metadata": {},
   "source": [
    "#### dropna()\n",
    "<li>dropna() with how and threshold parameter</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2760f62",
   "metadata": {},
   "source": [
    "#### Handle Missing Values using .replace() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c419fb9",
   "metadata": {},
   "source": [
    "#### Replacing Values Using a Dictionary (using columns and without using columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0dbe0",
   "metadata": {},
   "source": [
    "#### Replacing values using a regex\n",
    "<code>\n",
    "df.replace(original_value, replaced_value, regex = True)\n",
    "</code>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7f35d",
   "metadata": {},
   "source": [
    "#### Mapping values of a particular column using replace method\n",
    "<li>Replacing the list of values using another list of values</li>\n",
    "<li>Replacing values of a particular column using a dictionary</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1988ee8",
   "metadata": {},
   "source": [
    "#### GroupBy Functions\n",
    "<li>Pandas groupby is used for grouping the data according to the categories and apply a function to the categories.</li>\n",
    "<li>It also helps to aggregate data efficiently.</li>\n",
    "<li>Pandas dataframe.groupby() function is used to split the data into groups based on some criteria.</li>\n",
    "<code>\n",
    "    df.groupby(col_name, as_index, sort, dropna)\n",
    "</code>\n",
    "<li>It uses split, apply, combine principle to create a groupby dataframe.</li>\n",
    "<li>The groupby function accepts multiple parameters. Some of them are as follows:</li>\n",
    "<ol>\n",
    "    <li>col_name(required): the name of column against which you want to group elements.</li>\n",
    "    <li>as_index(optional): default = True, if you want to include groupby column as an index set it        to True else False.</li>\n",
    "    <li>sort(optional): default = True, if you want to sort the group based on keys then keep it as       True else False.</li>\n",
    "    <li>dropna(optional): default = True, if you keep it as false then it will also include Nan values     as a separate group.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c395f",
   "metadata": {},
   "source": [
    "### GroupBy Aggregation Functions\n",
    "<li>Here are some of the aggregating functions available in Pandas and quick summary of what it does.</li>\n",
    "<ol>\n",
    "    <li>mean(): Compute mean of groups for numeric columns</li>\n",
    "    <li>sum(): Compute sum of group values for numeric columns</li>\n",
    "    <li>size(): Compute group sizes</li>\n",
    "    <li>count(): Compute count of group</li>\n",
    "    <li>std(): Standard deviation of groups for numeric columns</li>\n",
    "    <li>var(): Compute variance of groups for numeric columns</li>\n",
    "    <li>describe(): Generates descriptive statistics</li>\n",
    "    <li>first(): Compute first of group values</li>\n",
    "    <li>last(): Compute last of group values</li>\n",
    "    <li>nth() : Take nth value, or a subset if n is a list</li>\n",
    "    <li>min(): Compute min of group values</li>\n",
    "    <li>max(): Compute max of group values</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3bf7e",
   "metadata": {},
   "source": [
    "#### Question\n",
    "<li>Read 'car_details.csv' file and create a pandas dataframe from this file.</li>\n",
    "<li>Find the maximum price for each of the car brand.</li>\n",
    "<li>Find the average price for each of the fuel types.</li>\n",
    "<li>Find the average km_driven for each of the seller_types.</li>\n",
    "<li>Find the count of each of the car names.</li>\n",
    "<li>Find the maximum km_driven for each of the owner types.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a0b50",
   "metadata": {},
   "source": [
    "####  Concatenating DataFrames\n",
    "<li>pandas.concat() function does all the heavy lifting of performing concatenation operations along with an axis</li>\n",
    "<li>If we want to join two individual dataframes and create a combined dataframe out of it, we can use concatenation operation for doing so.</li>\n",
    "<li>We can use concatenation operation along the rows(axis=0) as well as along the columns(axis = 1)</li>\n",
    "\n",
    "**syntax**\n",
    "\n",
    "<code>\n",
    "    pd.concat([df1,df2], axis, keys, ignore_index)\n",
    "</code>\n",
    "\n",
    "<li>df1 and df2 (required) are two dataframes which we want to merge.</li>\n",
    "<li>axis: axis to concatenate along, (possible values; 0(along the rows) and 1 (along the cols) default = 0 (along the rows).</li>\n",
    "<li>keys: sequence to add an identifier to the result indexes; default = None</li>\n",
    "<li>ignore_index: if True, do not use the index values along the concatenation axis; default = False</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345bd33a",
   "metadata": {},
   "source": [
    "#### Concatenating Dataframes along the rows\n",
    "![](images/concat_rows.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e0379",
   "metadata": {},
   "source": [
    "#### Concatenating DataFrames along columns\n",
    "![](images/concat_cols.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f1421",
   "metadata": {},
   "source": [
    "#### Merge\n",
    "<li>Pandas has full-featured, high performance in-memory join operations idiomatically very similar to relational databases like SQL.</li>\n",
    "<li>Pandas provides a single function, merge, as the entry point for all standard database join operations between DataFrame objects.</li>\n",
    "<li>The <b>merge()</b> method updates the content of two DataFrame by merging them together, using the specified method(s).</li>\n",
    "<li>We can use the parameters to control which values to keep and which to replace during merge operation.</li>\n",
    "<li>We can specify any type of join we want by using how parameter in merge method.</li>\n",
    "<li>There are four types of join operations. They are :</li>\n",
    "<ol>\n",
    "    <b><li>Inner join</li></b>\n",
    "    <b><li>Left join</li></b>\n",
    "    <b><li>Right join</li></b>\n",
    "    <b><li>Outer join</li></b>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ece457",
   "metadata": {},
   "source": [
    "#### 1. Inner Join\n",
    "![](images/inner_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47b8516",
   "metadata": {},
   "source": [
    "#### 2. Left Join\n",
    "\n",
    "![](images/left_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1879a7d",
   "metadata": {},
   "source": [
    "#### 3. Right Join\n",
    "\n",
    "![](images/right_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11437251",
   "metadata": {},
   "source": [
    "#### 4. Outer Join\n",
    "\n",
    "![](images/outer_join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9ae1b",
   "metadata": {},
   "source": [
    "#### Crosstab \n",
    "\n",
    "<li>Cross tabulation is used to quantitatively analyze the relationship between multiple variables.</li>\n",
    "<li>Cross tabulations — also referred to as contingency tables or crosstabs.</li>\n",
    "<li>They group variables together and enable researchers to understand the correlation between different variables.<li>\n",
    "<li>When we are doing multivariate analysis then we often came across crosstab() methods in pandas.</li>\n",
    "\n",
    "**Syntax**\n",
    "\n",
    "<code>\n",
    "    pd.crosstab(index, columns, values, margins, margin_names, normalize,aggfunc, dropna)\n",
    "</code>\n",
    "<ol>\n",
    "    <li>index : array-like, Series, or list of arrays/Series, Values to group by in the rows.</li>\n",
    "    <li>columns : array-like, Series, or list of arrays/Series, Values to group by in the columns.</li>\n",
    "    <li>values : array-like, optional, array of values to aggregate according to the factors. Requires `aggfunc` be specified.     </li>\n",
    "    <li>aggfunc : function, optional, If specified, requires `values` be specified as well.</li>\n",
    "    <li>margins : bool, default False, Add row/column margins (subtotals).</li>\n",
    "    <li>margins_name : str, default ‘All’, Name of the row/column that will contain the totals when margins is True.</li>\n",
    "    <li>dropna : bool, default True, Do not include columns whose entries are all NaN.</li>\n",
    "    <li>normalize: </li>\n",
    "    <ol>\n",
    "        <li>If passed ‘all’ or True, will normalize over all values.</li>\n",
    "        <li>If passed ‘index’ will normalize over each row.</li>\n",
    "        <li>If passed ‘columns’ will normalize over each column.</li>\n",
    "        <li>If margins is True, will also normalize margin values.</li>\n",
    "    </ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278baf6a",
   "metadata": {},
   "source": [
    "#### Pivot\n",
    "<li>pivot() method produces pivot table based on 3 columns of the DataFrame. Uses unique values from index / columns and fills with values.</li>\n",
    "\n",
    "    \n",
    "**syntax**\n",
    "<code>\n",
    "pd.pivot(index, columns, values)\n",
    "</code>\n",
    "    \n",
    "<b>Parameters:</b>\n",
    "<ol>\n",
    "    <li>index[ndarray] : Labels to use to make new frame’s index</li>\n",
    "    <li>columns[ndarray] : Labels to use to make new frame’s columns</li>\n",
    "    <li>values[ndarray] : Values to use for populating new frame’s values</li>\n",
    "</ol>\n",
    "\n",
    "**Returns: Reshaped DataFrame**\n",
    "\n",
    "**Exception: ValueError raised if there are any duplicates.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
